## KD-Tree

k-d tree即k-dimensional tree，常用来作空间划分及近邻搜索，是二叉空间划分树的一个特例。通常，对于维度为`k`，数据点数为`N`的数据集，k-d tree适用于`N≫2**k`的情形。

### 1. 最近邻搜索

一般来说，最近邻搜索是通过选择合适的数据相似度度量方法（博客：[数据相似性的度量方法总结](http://blog.csdn.net/guoziqing506/article/details/51779536)），计算所有数据与查询点的距离，比较大小即可。但是随着数据量的增大以及数据维度的提高，这种方法就很难在现实中应用了，因为效率会非常低。解决此类问题的思路基本分为两类：

1. 构建索引，快速排除与查询相关度不大的数据；
2. 降维，对数据条目先降维，再查询；

前者主要是为了解决数据量过大的问题，比较常见的有我们熟知的二叉搜索树，Merkel tree，B-tree，quad-tree等；后者主要是为了解决维度过大的问题，如局部敏感哈希算法：[LSH(Locality Sensitive Hashing)原理与实现](http://blog.csdn.net/guoziqing506/article/details/53019049)。

KD-Tree 是多维欧式空间分割，属于第一类。



### 2. 为什么需要KD-Tree ？

二叉搜索树（BST）查询的时间复杂度是O（logN），能提高数据查询速度，其原理是将一维空间的数据集进行分割，从而提高查询速度；

那在多维欧氏空间中，能否也构建类似原理的BST，来加快查询速度呢？由此诞生了KD-Tree。



### 3. KD-Tree构建

关键是如何进行**多维欧式空间划分**，一维空间只需要比较每个数值，多维空间每个条目由多个数值组成，怎么比较呢？

原理：**不比较全部的k维数据，而是选择其中某个维度比较，根据这个维度进行空间划分**。

那么问题就变为：

- 判断出在哪一个维度比较，也就是说，我们所要切割的面在哪一个维度上。当然这种切割需要遵循一个基本要求，那就是尽量通过这个维度的切割，使得数据集均分（为二）；
- 判断以哪个数据条目为依据划分。上面我们说，要使得数据集均分为二，那当然要选择一个合适的数据项，充当这个划分的“点”。

总结一下，就是要选择一个数据项，以这个数据项的某个维度的值为标准，同一维度的值大于这个值的数据项，划分为一部分，小于的划分为另一部分。根据这种划分来构建二叉树，就如同二叉搜索树那样。

现在，针对上面的两件事，我们需要做如下两个工作：

1. **确定划分维度**：这里维度的确定需要注意的是尽量要使得这个维度上所有数据项数值的分布尽可能地有大方差，也就是说，数据在这个维度上尽可能分散。这就好比是我们切东西，如果你切的是一根黄瓜，当让横着切要比竖着切更容易。所以我们应该先对所有维度的数值计算方差，选择方差最大的那个维度；
2. **选择充当切割标准的数据项**：那么只需要求得这个维度上所有数值的中位数即可；

至此，可以设计出kd-tree的构建算法了：

- 对于一个由n维数据构成的数据集，我们首先寻找方差最大的那个维度，设这个维度是`d`，然后找出在维度`d`上所有数据项的中位数`m`，按`m`划分数据集，一分为二，记这两个数据子集为Dl,DrDl,Dr。建立树节点，存储这次划分的情况（记录划分的维度`d`以及中位数`m`）；
- 对Dl,DrDl,Dr重复进行以上的划分，并且将新生成的树节点设置为上一次划分的左右孩子；
- 递归地进行以上两步，直到不能再划分为止（所谓不能划分是说当前节点中包含的数据项的数量小于了我们事先规定的阈值，不失一般性，我在此篇博客中默认这个阈值是2，也就是说所有叶子节点包含的数据项不会多于2条），不能再划分时，将对应的数据保存至最后的节点中，这些最后的节点也就是叶子节点。



#### kdtree 节点类与函数

| 类或函数           | 作用                                                         |
| ------------------ | ------------------------------------------------------------ |
| class-KdTreeNode   | kd-tree节点，包含以下6个Attributes                           |
| Attribute1-data    | 树节点属性，代表这个节点的数据项，其实是一个列表，如果不是叶子节点，则为空 |
| Attribute2-split   | 树节点属性，代表构建树时，对这个节点进行分割所依据的数据维度 |
| Attribute3-median  | 树节点属性，代表构建树时，所有上面split维度上数据的中位数    |
| Attribute4-left    | 树节点属性，代表左孩子                                       |
| Attribute5-right   | 树节点属性，代表右孩子                                       |
| Attribute6-parent  | 树节点属性，代表父亲节点，作用是在后面的搜索算法中用         |
| Attribute7-visited | 树节点属性，代表此节点是否被算法回溯遍历，作用是在后面的搜索算法中用 |
| func-getSplit      | 函数，得到所有维度中方差最大那个维度的序号                   |
| func-getMedian     | 函数，得到要分割的维度的中位数                               |

借用博客[Kd-Tree算法原理和开源实现代码](http://www.cnblogs.com/lysuns/articles/4710712.html)中的测试样例：数据集合(2,3), (5,4), (9,6), (4,7), (8,1), (7,2)，构建 kd-tree：

![img](https://cdn.jsdelivr.net/gh/SuilandCoder/PicStorage//img/20170224163636537)

图中，非叶节点的二元组中，第一个元素表示分割维度（split值），第二个维度表示，取得的中位数（median值）

### 4.搜索算法

#### 4.1 查询方法1：

[Kd-tree原理与实现](https://blog.csdn.net/guoziqing506/article/details/54692392?utm_medium=distribute.pc_relevant_t0.none-task-blog-searchFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-searchFromBaidu-1.control)

基本思路可分为如下3步：

1. 依照非叶节点中存储的分割维度以及中位数信息，自根节点始，从上向下搜索，直到到达叶子。遍历的原则当然是比较分割维度上，查询值与中位数的大小，设查询为Q，当前遍历到的节点为u，则若`Q[u.split] > u.median`，继续遍历u的右子树，反之，遍历左子树。
2. 遍历到叶子之后，计算叶子节点中与查询Q距离最小的数据项与查询的距离，记为`minDis`；其后执行“回溯”操作，回溯至当前节点的父节点，判断以Q为球心，以`minDis`为半径的超球面是否与这个父节点的另一个分支所代表的区域有交集（其实，这里的区域就是一个超矩形，它包含了所有这个节点代表的数据项）。如果没有，继续向上一层回溯；如果有，则按照1步继续执行，探底到叶子节点后，如果此时Q与这个叶子节点中的数据项有更小的距离，则更新`minDis`。
3. 持续进行以上两步，直到回溯至根节点，且根节点的两个分支都被“探测”过为止。

但是这个里面有一个难点：如何判断以查询Q为球心，以当前的`minDis`为半径的超球面与树中，一个非叶节点所代表的超矩形是否相交？
一种简单的方法是在构建树的时候直接给每个节点赋值一个超矩形，这个超矩形以一个树节点属性的形式存在。一般情况下是给出超矩形的一个最大点和一个最小点。判断的方法只需要看如下的两个条件是否都成立即可：

- `Q[u.split] + minDis >= minPoint[u.split]`
- `Q[u.split] - minDis >= maxPoint[u.split]`

其中，u为查询当前遍历到的节点的父节点，minPoint与maxPoint为u所代表的超矩形的最大点和最小点（所谓最大最小点，那二维空间的矩形来说，就是他的右上角的点和左下角的点，分别拥有这个矩形范围内各个维度上的最大值和最小值）

原因很简单，因为以Q为球心，以当前这个矩形区域的一个点为球面上一点的一个超球面，一定是经过了当前这个叶子所代表的区域，但是同时它不可能完全覆盖他的兄弟节点代表的区域。这个道理听上去有点乱，看下面这个图就能明白：

<img src="https://cdn.jsdelivr.net/gh/SuilandCoder/PicStorage//img/20170224143202821" alt="img" style="zoom:33%;" />

图中，Q1,Q2,Q3是三个查询点，线段AB是这个矩形空间的分割情况。可见，上面的结论书成立的，同时，我们还可以得到一个观点：只要`|Q[u.split] - u.median|<= minDis`那么就是与其兄弟节点所代表的区域相交。其实这个道理也可以通过数学上的推导得到，如果不能理解的话一试便知。

查询案例：

1. 查询点(8, 3)自根节点起，按照分割维度以及中位数向下遍历，找到叶子节点(9, 6)，此时算得的最小距离为√10；
2. 回溯，找到下一个需要处理的节点，也就是(8,1), (7,2)这个点（此时以(8,3)为圆心，以√10为半径的圆与这个点所代表区域相交），数据项 (7,2)与查询(8, 3)的距离更近，为√2，更新最小距离为√2；
3. 回溯，此时，非叶节点<2, 2>这个点所在的分支已经被访问过了，找到下一个需要处理的节点，<2, 4>这个点。不过计算距离发现，这个点所代表的区域并不与此时的圆相交，放弃对这一分支的搜索；
4. 回溯至根节点，并且此时根节点的两个分支都被考虑了，搜索结束，返回最近邻(7, 2)，最短距离是√2

#### 4.2 查询方法2：

[k-d tree算法原理及实现](https://leileiluoluo.com/posts/kdtree-algorithm-and-implementation.html)

给定点p，查询数据集中与其距离最近点的过程即为最近邻搜索。

如在上文构建好的k-d tree上搜索(3,5)的最近邻时，本文结合如下左右两图对二维空间的最近邻搜索过程作分析。

**a）**首先从根节点(7,2)出发，将当前最近邻设为(7,2)，对该k-d tree作深度优先遍历。以(3,5)为圆心，其到(7,2)的距离为半径画圆（多维空间为超球面），可以看出(8,1)右侧的区域与该圆不相交，所以(8,1)的右子树全部忽略。

**b）**接着走到(7,2)左子树根节点(5,4)，与原最近邻对比距离后，更新当前最近邻为(5,4)。以(3,5)为圆心，其到(5,4)的距离为半径画圆，发现(7,2)右侧的区域与该圆不相交，忽略该侧所有节点，这样(7,2)的整个右子树被标记为已忽略。

**c）**遍历完(5,4)的左右叶子节点，发现与当前最优距离相等，不更新最近邻。所以(3,5)的最近邻为(5,4)。

![img](https://cdn.jsdelivr.net/gh/SuilandCoder/PicStorage//img/nn-searching-in-2d-space.png)![img](https://cdn.jsdelivr.net/gh/SuilandCoder/PicStorage//img/nn-searching-in-kd-tree.png)